# pipeline.yml (VERSION ACTUALIZADA)
version: 2
stages:
  - name: generate
    prompt: 01_agent_dominio.md
    provider: openai # O el proveedor global por defecto (ej. gemini, ollama)
    model: gpt-4o-mini # Ejemplo de modelo específico para OpenAI
    temperature: 0.7
    max_tokens: 3000

  - name: validate_hard

  - name: validate_logic
    prompt: 02_agent_razonamiento.md
    provider: gemini # Ejemplo: usar Gemini para lógica
    model: gemini-1.5-pro
    temperature: 0.1
    max_tokens: 1500
    on_fail:
      goto: refine_item_logic
      max_attempts: 2
      final_status_on_exhaustion: "failed_logic_validation_after_retries"

  - name: refine_item_logic
    prompt: 03_agente_refinador_razonamiento.md
    provider: gemini # Mismo proveedor que el validador lógico
    model: gemini-1.5-pro
    temperature: 0.3
    max_tokens: 2500

  - name: validate_style
    prompt: 04_agent_style_validator.md # (Asumiendo que este prompt se creará)
    provider: openai # Ejemplo: usar OpenAI para validación de estilo
    model: gpt-4o-mini # O un modelo más económico como "gpt-3.5-turbo"
    temperature: 0.5
    max_tokens: 1000
    on_fail:
      goto: refine_item_style
      max_attempts: 2
      final_status_on_exhaustion: "failed_style_validation_after_retries"

  - name: refine_item_style
    prompt: 04_agente_refinador_estilo.md
    provider: openai # Mismo proveedor que el validador de estilo
    model: gpt-4o-mini
    temperature: 0.3
    max_tokens: 2000

  - name: validate_policy
    prompt: 05_agent_politicas.md
    provider: openai # Ejemplo: usar OpenAI para políticas
    model: gpt-4o-mini
    temperature: 0.1
    max_tokens: 1500
    on_fail:
      goto: refine_item_policy
      max_attempts: 2
      final_status_on_exhaustion: "failed_policy_validation_after_retries"

  - name: refine_item_policy
    prompt: 06_agente_refinador_politicas.md
    provider: openai # Mismo proveedor que el validador de políticas
    model: gpt-4o-mini
    temperature: 0.3
    max_tokens: 2500

  - name: validate_soft
    # No usa LLM, no necesita provider

  - name: finalize_item
    prompt: 07_agent_final.md
    provider: gemini # Ejemplo: usar Gemini para la etapa final
    model: gemini-1.5-pro
    temperature: 0.2
    max_tokens: 2000

  - name: persist
    # No usa LLM, no necesita provider
